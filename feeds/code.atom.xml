<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Johan Carlin</title><link href="http://www.johancarlin.com/" rel="alternate"></link><link href="http://www.johancarlin.com/feeds/code.atom.xml" rel="self"></link><id>http://www.johancarlin.com/</id><updated>2016-01-05T10:49:58+00:00</updated><entry><title>Cloud-free folder syncing with Unison</title><link href="http://www.johancarlin.com/cloud-free-folder-syncing-with-unison.html" rel="alternate"></link><updated>2016-01-05T10:49:58+00:00</updated><author><name>Johan Carlin</name></author><id>tag:www.johancarlin.com,2016-01-05:cloud-free-folder-syncing-with-unison.html</id><summary type="html">&lt;p&gt;Syncing folders between computers can be surprisingly complicated if you
work for &lt;a href="http://www.mrc.ac.uk"&gt;an academic institution that takes a dim view of Dropbox and
other cloud-based solutions&lt;/a&gt;. You are also sure to
run out of space fast if you use it to sync e.g. neuroimaging data.
&lt;a href="https://www.cis.upenn.edu/~bcpierce/unison"&gt;Unison&lt;/a&gt; is a free command-line
solution for direct computer-to-computer sync. It is basically a clever
wrapper around rsync, which takes care of all the niggly details of getting
two-way sync working properly. It also provides a nice command-line
interface for resolving sync conflicts (far better than e.g. Evernote&amp;#8217;s &lt;span class="caps"&gt;GUI&lt;/span&gt;
for the same&amp;nbsp;thing).&lt;/p&gt;
&lt;p&gt;Getting Unison up and running for your setup can be complicated. Here I
present a simple shell script that takes care of the standard case of
syncing two computers over &lt;span class="caps"&gt;SSH&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In general, my solution assumes that one computer is used to issue the
unison command (the client, which is probably your laptop or home computer)
which then connects and syncs with another computer (the remote, which is
probably a server or a desktop computer at your place of work). You could
set this up to run automatically as a cron or launchd, but I prefer to
issue the command manually at the end of the workday to make sure that I
have saved all changes&amp;nbsp;first.&lt;/p&gt;
&lt;h2&gt;Installing&amp;nbsp;unison&lt;/h2&gt;
&lt;p&gt;Unison is available through various package managers, e.g. macports and
brew. The main stumbling point here is to ensure unison is available on the
remote (the computer you are syncing to). On my setup (brew with &lt;span class="caps"&gt;OS&lt;/span&gt; X
Yosemite), unison returned &lt;code&gt;bash: unison:
command not found&lt;/code&gt;, even though unison was clearly availabe when connecting
to the remote over &lt;span class="caps"&gt;SSH&lt;/span&gt;. By contrast, &lt;code&gt;ssh [client] unison&lt;/code&gt; returned an
error, thus revealing that unison was only getting
added to the path in interactive shells (&lt;a href="http://unix.stackexchange.com/questions/79723/why-do-ssh-host-echo-path-and-printing-the-path-after-sshing-into-the-machi"&gt;which are not the same as login
shells used by scripts&lt;/a&gt;). In the end I manually added
/usr/local/bin to my path in .bashrc to get around this issue
(.bash_profile wouldn&amp;#8217;t work since this isn&amp;#8217;t sourced by non-interactive&amp;nbsp;shells).&lt;/p&gt;
&lt;h2&gt;Configuring&amp;nbsp;unison&lt;/h2&gt;
&lt;p&gt;The &lt;a href="https://gist.github.com/jooh/bbdf2b311017b3453830"&gt;unisync&lt;/a&gt; script
below provides the basic sync functionality for syncing between two folders
named unibox in the user&amp;#8217;s home directory. The first input argument
specifies the hostname, while the second provides the username for the
remote. By default, the username for client and remote as assumed to be the&amp;nbsp;same.&lt;/p&gt;
&lt;div class="gist"&gt;
    &lt;script src='https://gist.github.com/bbdf2b311017b3453830.js'&gt;&lt;/script&gt;
    &lt;noscript&gt;
        &lt;pre&gt;&lt;code&gt;#!/bin/tcsh
#
#       by: Johan Carlin
#     date: 8/9/2014
#  purpose: sync folders between computers. Assumes that both are available
#   on the local network (ie you are using VPN if the host is behind a
#   firewall)
#    usage: unisync [ucl] [j.carlin]

# get optional input
if ($#argv &gt;= 1) then
  set hostname="$1"
else
  set hostname=ucl
endif

if ($#argv == 2) then
  set touser="$2"
else
  set touser=$USER
endif

set fromdir=/Users/$USER/unibox
set todir=/Users/$touser/unibox

# auto should mean that we get batch mode if there are no conflicts, and
# interactive mode otherwise
unison $fromdir "ssh://"$hostname"/"$todir -auto
&lt;/code&gt;&lt;/pre&gt;
    &lt;/noscript&gt;
&lt;/div&gt;
&lt;p&gt;So for instance, my standard usage is &lt;code&gt;unisync ucl j.carlin&lt;/code&gt;, where ucl is
an alias or shortcut for my full &lt;span class="caps"&gt;SSH&lt;/span&gt; connection stored in ssh/.config, and
j.carlin is my username which is necessary here because it is different
from my username on the&amp;nbsp;client.&lt;/p&gt;</summary><category term="shell"></category><category term="scientific computing"></category></entry><entry><title>Reproducible scientific python setup with (Ana) Conda</title><link href="http://www.johancarlin.com/reproducible-scientific-python-setup-with-ana-conda.html" rel="alternate"></link><updated>2015-12-11T19:06:58+00:00</updated><author><name>Johan Carlin</name></author><id>tag:www.johancarlin.com,2015-12-11:reproducible-scientific-python-setup-with-ana-conda.html</id><summary type="html">&lt;p&gt;Getting a scientific python install up and running is still way too
complicated. In this post I describe how I use a conda to keep a
reproducible record of the packages I&amp;nbsp;use.&lt;/p&gt;
&lt;p&gt;In the past, I have usually hacked together my own developing environment
through whatever tools were most convenient (pip, github clones, built-in
packages from expansive standard python distros). This is a workable
solution if you&amp;#8217;re only doing it once, but it can be quite challenge to
achieve the exact same python environment on a new machine. This is
annoying in lots of contexts, but it&amp;#8217;s especially problematic for
scientific computing because it means others (or even your future self) may
not be able to reproduce your published&amp;nbsp;results.&lt;/p&gt;
&lt;p&gt;My solution to this issue is to use
&lt;a href="http://conda.pydata.org/docs/index.html"&gt;Conda&lt;/a&gt;, which forms an
independent part of the Anaconda python distro (I use the lighter
mini-conda). At its core, Conda is a package manager which tries to be
smart about managing your python environment. There are many competitors in
this area (the classic solution is pip combined with virtualenv, brew and
macports are other possibilities), but Conda has a few useful features that
collectively make it preferable for scientific&amp;nbsp;computing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Conda packages are distributed in compiled form, which avoids all
  build-related issues (e.g., missing dependencies, broken compilers, weird
  build environments). If the package has been built properly, it is
  literally plug and play. For a taste of how smoothly this works with
  complex packages, try &lt;code&gt;conda install mayavi&lt;/code&gt; compared to &lt;code&gt;brew install
  mayavi&lt;/code&gt; and see what you&amp;nbsp;get.&lt;/li&gt;
&lt;li&gt;If a conda package is not available, it is surprisingly easy to build one
  from python libraries.  Most pip packages can be built for conda with two
  commands: &lt;code&gt;conda skeleton pypi [pip package]&lt;/code&gt; followed by &lt;code&gt;conda build
  [pip package]&lt;/code&gt;.  Adapting github repos requires a bit more manual
  editing of a &lt;span class="caps"&gt;YAML&lt;/span&gt; file but even this is simple enough (see e.g. &lt;a href="https://github.com/jooh/neuroconda/tree/master/pycortex"&gt;this
  pycortex recipe I
  wrote&lt;/a&gt;). Under
  the hood, there&amp;#8217;s quite a bit of cleverness going on with e.g. converting
  absolute paths to relative to enable this to work as smoothly as it&amp;nbsp;does.&lt;/li&gt;
&lt;li&gt;Conda includes a free package repository at
  &lt;a href="http://anaconda.org"&gt;anaconda.org&lt;/a&gt;, where users can upload packages.
  At build time, users are nudged toward setting &lt;code&gt;anaconda_upload: yes&lt;/code&gt; in
  their .condarc files, which means that any successful build is
  uploaded to your anaconda.org repo. This option appears to be popular
  because a huge number of user-built packages are available here. This is
  useful for quickly checking out more obscure packages that aren&amp;#8217;t in
  the official conda&amp;nbsp;channel.&lt;/li&gt;
&lt;li&gt;That being said, for reproducibility it is probably a better idea to
  build packages yourself and upload them to your own repository since
  other users can otherwise break your dependencies by removing or altering
  the package you&amp;#8217;re channeling. Uploading your own builds has the added
  advantage of solving your deployment issues &amp;#8212; all you have to do on a new
  machine is add your repository to the set conda will search when
  installing packages (e.g., &lt;code&gt;conda config --add channels jcarlin&lt;/code&gt;), and
  the standard conda install command will just&amp;nbsp;work.&lt;/li&gt;
&lt;li&gt;Conda&amp;#8217;s environment handling is quite good, and seems to err on the side
  of safety at the expense of disk space (ie, copy everything) compared to
  e.g. brew. I have yet to bump into any interactions between different
  environments. Generally, it&amp;#8217;s a good idea to have a different environment
  for each broad task you use python for (I use one for psychopy, one for
  neuroimaging analysis and one for web development), since packages
  sometimes require different versions of the same modules. Conda tries to
  manage such situations, but often the compromise is to downgrade core
  packages (e.g. numpy) to fairly old&amp;nbsp;versions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In summary, my entire python environment is now made up of Conda packages,
which is neat because it means that I can reproduce my python setup
anywhere. There is a bit of overhead in going this route (especially if you
want to avoid having dependencies from other anaconda.org users), but this
should be recouped quickly down the road as the code gets deployed to
psychophysics test laptops, cloud compute, other lab&amp;nbsp;members&amp;#8230;&lt;/p&gt;</summary><category term="python"></category><category term="data science"></category><category term="conda"></category><category term="anaconda"></category><category term="scientific computing"></category><category term="virtual environment"></category></entry></feed>